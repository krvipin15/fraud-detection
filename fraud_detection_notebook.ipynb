{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a025b57d",
   "metadata": {},
   "source": [
    "# Fraud Detection System using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd6ae0",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Credit card fraud poses a serious risk to financial institutions, with fraudulent transactions being extremely rare compared to legitimate ones. This results in highly imbalanced datasets, where traditional machine learning models often fail to detect rare fraud cases. The objective of this project is to build a fraud detection system that can accurately identify fraudulent transactions while minimizing false alarms, leveraging resampling techniques, robust evaluation metrics, and MLflow for experiment tracking and deployment readiness.\n",
    "\n",
    "### Approach\n",
    "\n",
    "1. **Data Understanding & Exploration**\n",
    "2. **Data Preprocessing**\n",
    "3. **Feature Engineering**\n",
    "4. **Experiment Tracking with MLflow**\n",
    "5. **Model Building**\n",
    "6. **Model Evaluation**\n",
    "7. **Hyperparameter Tuning**\n",
    "8. **Final Model Selection & Deployment**\n",
    "9. **Conclusion & Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19a050",
   "metadata": {},
   "source": [
    "## Data Understanding and Exploration\n",
    "\n",
    "The dataset contains credit card transactions made by European cardholders in Sept 2013. It includes 284,807 transactions, out of which only 492 are fraudulent, making the dataset highly imbalanced — fraud cases represent just 0.172% of the total.\n",
    "\n",
    "To preserve confidentiality, all features (except 'Time' and 'Amount') have been transformed using Principal Component Analysis (PCA), resulting in 28 anonymized features labeled `V1` to `V28`.\n",
    "- `Time`: This shows how many seconds have passed since the first transaction in the dataset.\n",
    "- `Amount`: It is the transaction value.\n",
    "- `Class`: It is the target variable, where 1 indicates fraud and 0 indicates a legitimate transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73afc5",
   "metadata": {},
   "source": [
    "### 1. Basic Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f44c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import tempfile\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import mlflow.xgboost\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from optuna.exceptions import TrialPruned\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_score,\n",
    "                             recall_score, precision_recall_curve, f1_score,roc_curve,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a10ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "dir_path = Path(\"data\")\n",
    "dir_path.mkdir(exist_ok=True)\n",
    "zip_file_path = dir_path / \"creditcardfraud.zip\"\n",
    "\n",
    "if not dir_path.glob(\"*.csv\"):\n",
    "    # Download the ZIP file\n",
    "    !curl -L -o {zip_file_path} https://www.kaggle.com/api/v1/datasets/download/mlg-ulb/creditcardfraud\n",
    "\n",
    "    # Unzip the data file\n",
    "    !unzip -o {zip_file_path} -d {dir_path}\n",
    "\n",
    "    # Remove the ZIP file\n",
    "    zip_file_path.unlink()\n",
    "else:\n",
    "    print(\"Dataset already present in the directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "csv_files = list(dir_path.glob('*.csv'))\n",
    "if csv_files:\n",
    "    print(f\"Loading `{csv_files[0]}` as DataFrame\")\n",
    "    df = pd.read_csv(csv_files[0])\n",
    "    print(\"Shape of the DataFrame: \", df.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(\"No CSV file found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20460fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top three rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afac239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a69d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Info\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a80ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class imbalance\n",
    "df.value_counts(subset=[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04561ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate count if time column is removed\n",
    "df.drop(columns=['Time']).duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca61b4d",
   "metadata": {},
   "source": [
    "#### Observations till now\n",
    "* **Shape and Features**: The dataset contains 284,807 transactions and 31 columns. The features `V1` through `V28` are anonymized (due to PCA), with Time and Amount being the only non-anonymized features.\n",
    "* **Data Integrity**: There are no missing or null values in the dataset.\n",
    "* **Class Imbalance**: The dataset is highly imbalanced, with fraudulent transactions (Class=1) making up only 0.173% of the total.\n",
    "* **Duplicate Records**: There are 1,081 fully duplicated rows. This number increases significantly to 9,144 when the `Time` column is excluded, indicating that many transactions are identical in all respects except for the time they occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee535a",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558aa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the time column\n",
    "df.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Drop the duplicated rows\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Imbalance data after removing duplicates\n",
    "df.value_counts(subset=[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80cceb",
   "metadata": {},
   "source": [
    "#### 2.1 Univariate Analysis\n",
    "\n",
    "`V1`-`V28` columns already came through PCA which centers the data (mean ≈ 0) and scales variance. Most algorithms (especially tree-based) can use these directly without any extra preprocessing, so we will only plot `Amount` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distribution\n",
    "sns.histplot(data=df, x='Amount', kde=True)\n",
    "plt.title(\"Distribution of Transaction Amount\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fcaf7a",
   "metadata": {},
   "source": [
    "The distribution is highly skewed to the right, with the majority of transactions involving small amounts. Apply log transformation to handle the skewness and drop the skewed `Amount` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24873bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transformation for skew data\n",
    "df[\"Log_Amount\"] = np.log1p(df['Amount'])\n",
    "df.drop(\"Amount\", axis=1, inplace=True)\n",
    "\n",
    "# Plot the log amount\n",
    "sns.histplot(data=df, x=\"Log_Amount\", kde=True)\n",
    "plt.title(\"Distribution of Log Transformed Amount\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c229789",
   "metadata": {},
   "source": [
    "#### 2.2    Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02893fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outliers using Boxplot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='Class', y='Log_Amount', data=df)\n",
    "plt.title('Log Transaction Amount by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3728a7",
   "metadata": {},
   "source": [
    "The outliers present in the legit transaction class can be rare case and is fine to keep for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995da5d",
   "metadata": {},
   "source": [
    "### 2.3 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(df.corr(), cmap='Blues', annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27595c",
   "metadata": {},
   "source": [
    "The features are mostly uncorrelated with each other means no linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea16cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 correlated features with target\n",
    "corr_with_target = df.corrwith(df[\"Class\"], method=\"pearson\").abs().drop(labels=[\"Class\"], errors=\"ignore\")\n",
    "corr_with_target.sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa56c8f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd594b39",
   "metadata": {},
   "source": [
    "### 1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprate the features and target\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Initial Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Shape after the split\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a9c29",
   "metadata": {},
   "source": [
    "### 2. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc850c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Scale all features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log amount\n",
    "sns.histplot(data=pd.DataFrame(X_train_scaled, columns=X_train.columns), x=\"Log_Amount\", kde=True)\n",
    "plt.title(\"Distribution of Log Transformed Amount\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd7610",
   "metadata": {},
   "source": [
    "### 3. Class Imbalance Handling\n",
    "\n",
    "#### 3.1 Resampling using Tomek (Under-Sampling Technique) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b44049",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek = TomekLinks(n_jobs=-1)\n",
    "X_train_res1, y_train_res1 = tomek.fit_resample(X_train_scaled, y_train)\n",
    "X_train_res1.shape, y_train_res1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8384f3",
   "metadata": {},
   "source": [
    "#### 3.2 Resampling using SMOTE (Over-Sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res2, y_train_res2 = smote.fit_resample(X_train_scaled, y_train)\n",
    "X_train_res2.shape, y_train_res2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b94a8a",
   "metadata": {},
   "source": [
    "#### 3.3 Resampling using SMOTE + Tomek (Hybrid-Sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c12a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "X_train_res3, y_train_res3 = smote_tomek.fit_resample(X_train_scaled, y_train)\n",
    "X_train_res3.shape, y_train_res3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79e92c",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1714cc",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7de879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow experiment setup\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(experiment_name=\"fraud_detection_baseline\")\n",
    "\n",
    "# Map pre-resampled datasets to names\n",
    "resampled_datasets = {\n",
    "    \"TomekLinks\": (X_train_res1, y_train_res1),\n",
    "    \"SMOTE\": (X_train_res2, y_train_res2),\n",
    "    \"SMOTE_Tomek\": (X_train_res3, y_train_res3),\n",
    "}\n",
    "\n",
    "# Outer training loop\n",
    "for resample_name, (X_train_res, y_train_res) in resampled_datasets.items():\n",
    "    print(\"---\"*10 + f\" Training on {resample_name} resampled data \" + \"---\"*10)\n",
    "\n",
    "    # Per-resample imbalance for XGBoost\n",
    "    neg_count = int(np.sum(y_train_res == 0))\n",
    "    pos_count = int(np.sum(y_train_res == 1))\n",
    "    scale_pos_weight_val = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "\n",
    "    # Models (CPU-friendly hyperparams)\n",
    "    models = {\n",
    "        \"MLPClassifier\": MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=1e-4,\n",
    "            learning_rate_init=1e-3,\n",
    "            max_iter=200,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        ),\n",
    "        \"LogisticRegression\": LogisticRegression(\n",
    "            penalty='l2',\n",
    "            C=1.0,\n",
    "            solver='lbfgs',\n",
    "            max_iter=500,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            max_features='sqrt',\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            booster='gbtree',\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            min_child_weight=5,\n",
    "            gamma=0,\n",
    "            reg_lambda=1,\n",
    "            reg_alpha=0,\n",
    "            scale_pos_weight=scale_pos_weight_val,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            tree_method='hist'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"- Training {model_name} model\")\n",
    "        with mlflow.start_run(run_name=f\"{resample_name}_{model_name}\"):\n",
    "\n",
    "            # Train\n",
    "            if model_name == \"XGBoost\":\n",
    "                model.set_params(early_stopping_rounds=50)\n",
    "                model.fit(X_train_res, y_train_res, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
    "            else:\n",
    "                model.fit(X_train_res, y_train_res)\n",
    "\n",
    "            # Predictions & probabilities\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            # safe get probabilities (fallback to decision function is not needed here; all models used have predict_proba)\n",
    "            try:\n",
    "                y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            except Exception:\n",
    "                # fallback: use decision_function and scale to 0-1 via sigmoid (rare for these models)\n",
    "                from scipy.special import expit\n",
    "                y_prob = expit(model.decision_function(X_test_scaled))\n",
    "\n",
    "            # Core metrics\n",
    "            ap_score = average_precision_score(y_test, y_prob)\n",
    "            metrics = {\n",
    "                \"precision\": precision_score(y_test, y_pred),\n",
    "                \"recall\": recall_score(y_test, y_pred),\n",
    "                \"f1\": f1_score(y_test, y_pred),\n",
    "                \"roc_auc\": roc_auc_score(y_test, y_prob),\n",
    "                \"avg_precision\": float(ap_score)\n",
    "            }\n",
    "            # log metrics\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.log_params({\"resampling\": resample_name, \"model\": model_name})\n",
    "\n",
    "            # --- Confusion Matrix artifact ---\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            fig_cm, ax_cm = plt.subplots()\n",
    "            ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=ax_cm, cmap='Blues', colorbar=True)\n",
    "            fig_cm.tight_layout()\n",
    "            mlflow.log_figure(fig_cm, f\"confusion_matrix_{resample_name}_{model_name}.png\")\n",
    "            plt.close(fig_cm)\n",
    "\n",
    "            # --- ROC Curve artifact ---\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "            fig_roc, ax_roc = plt.subplots()\n",
    "            ax_roc.plot(fpr, tpr, label=f\"AUC = {metrics['roc_auc']:.3f}\")\n",
    "            ax_roc.plot([0, 1], [0, 1], 'k--')\n",
    "            ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "            ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "            ax_roc.set_title(\"ROC Curve\")\n",
    "            ax_roc.legend(loc=\"lower right\")\n",
    "            fig_roc.tight_layout()\n",
    "            mlflow.log_figure(fig_roc, f\"roc_curve_{resample_name}_{model_name}.png\")\n",
    "            plt.close(fig_roc)\n",
    "\n",
    "            # --- Precision-Recall Curve artifact ---\n",
    "            prec, rec, _ = precision_recall_curve(y_test, y_prob)\n",
    "            fig_pr, ax_pr = plt.subplots()\n",
    "            ax_pr.plot(rec, prec, label=f\"AP = {ap_score:.3f}\")\n",
    "            ax_pr.set_xlabel(\"Recall\")\n",
    "            ax_pr.set_ylabel(\"Precision\")\n",
    "            ax_pr.set_title(\"Precision–Recall Curve\")\n",
    "            ax_pr.legend(loc=\"lower left\")\n",
    "            fig_pr.tight_layout()\n",
    "            mlflow.log_figure(fig_pr, f\"pr_curve_{resample_name}_{model_name}.png\")\n",
    "            plt.close(fig_pr)\n",
    "\n",
    "            # --- Minimal metadata ---\n",
    "            try:\n",
    "                mlflow.set_tags({\n",
    "                    \"project\": \"fraud_detection\",\n",
    "                    \"owner\": \"Vipin Kumar\",\n",
    "                    \"model\": model_name,\n",
    "                    \"resampling\": resample_name,\n",
    "                    \"hardware\": \"CPU\"\n",
    "                })\n",
    "                # log hyperparameters\n",
    "                for k, v in model.get_params().items():\n",
    "                    try:\n",
    "                        mlflow.log_param(f\"hyperparameter_{k}\", v)\n",
    "                    except Exception:\n",
    "                        mlflow.log_param(f\"hyperparameter_{k}\", str(v))\n",
    "                # dataset summary as small json artifact & params\n",
    "                dataset_stats = {\n",
    "                    \"X_train_shape\": X_train_res.shape,\n",
    "                    \"y_train_shape\": y_train_res.shape,\n",
    "                    \"X_test_shape\": getattr(X_test_scaled, \"shape\", None),\n",
    "                    \"y_test_shape\": getattr(y_test, \"shape\", None),\n",
    "                    \"train_neg\": int((y_train_res == 0).sum()),\n",
    "                    \"train_pos\": int((y_train_res == 1).sum()),\n",
    "                    \"scale_pos_weight\": float(scale_pos_weight_val),\n",
    "                }\n",
    "                mlflow.log_dict(dataset_stats, f\"dataset_stats_{resample_name}_{model_name}.json\")\n",
    "                mlflow.log_params({\n",
    "                    \"train_pos\": dataset_stats[\"train_pos\"],\n",
    "                    \"train_neg\": dataset_stats[\"train_neg\"],\n",
    "                    \"scale_pos_weight\": dataset_stats[\"scale_pos_weight\"]\n",
    "                })\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # --- Log model with signature & input_example (preferred) ---\n",
    "            try:\n",
    "                # Build a small input example from test set\n",
    "                if isinstance(X_test_scaled, pd.DataFrame):\n",
    "                    input_example = X_test_scaled.head(5)\n",
    "                else:\n",
    "                    input_example = pd.DataFrame(X_test_scaled[:5])\n",
    "                # try infer signature using predict_proba\n",
    "                try:\n",
    "                    preds_example = model.predict_proba(input_example)\n",
    "                    signature = infer_signature(input_example, preds_example)\n",
    "                except Exception:\n",
    "                    signature = None\n",
    "                # log model with name=\"model\"\n",
    "                log_kwargs = {\"input_example\": input_example}\n",
    "                if signature is not None:\n",
    "                    log_kwargs[\"signature\"] = signature\n",
    "                mlflow.sklearn.log_model(model, name=\"model\", **log_kwargs)\n",
    "            except Exception as e:\n",
    "                # fallback to older param name if needed\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(model, name=\"model\")\n",
    "                except Exception:\n",
    "                    print(\"Model logging failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f713203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get experiment ID by name\n",
    "experiment_name = \"fraud_detection_baseline\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Experiment '{experiment_name}' not found.\")\n",
    "\n",
    "# Fetch all runs for this experiment\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], order_by=[\"metrics.avg_precision DESC\"])\n",
    "\n",
    "# Keep only relevant columns\n",
    "results_df = runs[[\"params.resampling\", \"params.model\", \"metrics.precision\", \"metrics.avg_precision\", \"metrics.recall\", \"metrics.f1\", \"metrics.roc_auc\",]]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc623",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. Impact of Resampling:\n",
    "    * Models trained on data resampled with **TomekLinks** demonstrated the best overall performance, achieving a strong balance between precision and recall. These models were effective at identifying fraud without flagging an excessive number of legitimate transactions.\n",
    "    * Models trained with **SMOTE** and **SMOTE+Tomek** achieved very high recall (catching most of the fraud cases) but at the cost of extremely low precision. This would lead to a high number of false positives, which is undesirable in a real-world scenario.\n",
    "\n",
    "2. Best Model Performance:\n",
    "    * The **XGBoost** classifier trained on the **TomekLinks** resampled data emerged as the top-performing model.\n",
    "    * This combination achieved the highest Average Precision score of 0.827 and a high F1-score of 0.822. It also had a strong recall of 0.80 and a precision of 0.844."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04708e",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow tracking\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"fraud_detection_tuning\")\n",
    "\n",
    "# Initialize MLflow client for model registry operations\n",
    "client = MlflowClient()\n",
    "\n",
    "# Global variables to track best model\n",
    "best_avg_precision = 0\n",
    "best_run_id = None\n",
    "best_model = None\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274492ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global best_avg_precision, best_run_id, best_model, best_params\n",
    "\n",
    "    # Suggest hyperparameters optimized for CPU (i5 10th gen, 12GB RAM)\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    # Start MLflow run for this trial\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        # Calculate scale_pos_weight for resampled data\n",
    "        neg_count = int(np.sum(y_train_res1 == 0))\n",
    "        pos_count = int(np.sum(y_train_res1 == 1))\n",
    "        scale_pos_weight_val = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "\n",
    "        # Update params with scale_pos_weight\n",
    "        params['scale_pos_weight'] = scale_pos_weight_val\n",
    "\n",
    "        # Train model on resampled training data\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train_res1, y_train_res1, verbose=False)\n",
    "\n",
    "        # Predict on test set\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "        y_test_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # Calculate test metrics\n",
    "        test_precision = precision_score(y_test, y_test_pred)\n",
    "        test_recall = recall_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "        test_avg_precision = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "        # Log all hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Log test metrics\n",
    "        test_metrics = {\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_roc_auc\": test_roc_auc,\n",
    "            \"test_avg_precision\": test_avg_precision,\n",
    "        }\n",
    "        mlflow.log_metrics(test_metrics)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if test_avg_precision > best_avg_precision:\n",
    "\n",
    "            # Create and log visualizations\n",
    "            # Confusion Matrix\n",
    "            cm = confusion_matrix(y_test, y_test_pred)\n",
    "            fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "            ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=ax_cm, cmap='Blues', colorbar=True)\n",
    "            ax_cm.set_title(f'Confusion Matrix - Trial {trial.number}')\n",
    "            fig_cm.tight_layout()\n",
    "            mlflow.log_figure(fig_cm, f\"confusion_matrix_trial_{trial.number}.png\")\n",
    "            plt.close(fig_cm)\n",
    "\n",
    "            # ROC Curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "            fig_roc, ax_roc = plt.subplots(figsize=(8, 6))\n",
    "            ax_roc.plot(fpr, tpr, label=f\"AUC = {test_roc_auc:.3f}\")\n",
    "            ax_roc.plot([0, 1], [0, 1], 'k--')\n",
    "            ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "            ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "            ax_roc.set_title(f\"ROC Curve - Trial {trial.number}\")\n",
    "            ax_roc.legend(loc=\"lower right\")\n",
    "            fig_roc.tight_layout()\n",
    "            mlflow.log_figure(fig_roc, f\"roc_curve_trial_{trial.number}.png\")\n",
    "            plt.close(fig_roc)\n",
    "\n",
    "            # Precision-Recall Curve\n",
    "            prec, rec, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "            fig_pr, ax_pr = plt.subplots(figsize=(8, 6))\n",
    "            ax_pr.plot(rec, prec, label=f\"AP = {test_avg_precision:.3f}\")\n",
    "            ax_pr.set_xlabel(\"Recall\")\n",
    "            ax_pr.set_ylabel(\"Precision\")\n",
    "            ax_pr.set_title(f\"Precision-Recall Curve - Trial {trial.number}\")\n",
    "            ax_pr.legend(loc=\"lower left\")\n",
    "            fig_pr.tight_layout()\n",
    "            mlflow.log_figure(fig_pr, f\"pr_curve_trial_{trial.number}.png\")\n",
    "            plt.close(fig_pr)\n",
    "\n",
    "            # Log model with signature and input example\n",
    "            try:\n",
    "                if hasattr(X_test_scaled, 'head'):\n",
    "                    input_example = X_test_scaled.head(5)\n",
    "                else:\n",
    "                    input_example = pd.DataFrame(X_test_scaled[:5])\n",
    "\n",
    "                signature = infer_signature(input_example, model.predict_proba(input_example))\n",
    "                mlflow.xgboost.log_model(\n",
    "                    model,\n",
    "                    name=\"model\",\n",
    "                    signature=signature,\n",
    "                    input_example=input_example\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Model logging failed for trial {trial.number}: {e}\")\n",
    "                mlflow.xgboost.log_model(model, name=\"model\")\n",
    "\n",
    "            # Update best model tracking\n",
    "            best_avg_precision = test_avg_precision\n",
    "            best_run_id = mlflow.active_run().info.run_id\n",
    "            best_model = model\n",
    "            best_params = params.copy()\n",
    "\n",
    "            print(f\"New best model found in trial {trial.number}! Test Avg Precision: {test_avg_precision:.4f}\")\n",
    "\n",
    "        # Log tags\n",
    "        mlflow.set_tags({\n",
    "            \"project\": \"fraud_detection_tuning\",\n",
    "            \"model\": \"XGBoost\",\n",
    "            \"resampling\": \"TomekLinks\",\n",
    "            \"optimization_metric\": \"avg_precision\",\n",
    "            \"trial_number\": trial.number\n",
    "        })\n",
    "\n",
    "        # Log dataset info\n",
    "        dataset_info = {\n",
    "            \"train_resampled_shape\": X_train_res1.shape,\n",
    "            \"test_shape\": X_test_scaled.shape,\n",
    "            \"resampling_method\": \"TomekLinks\",\n",
    "            \"scale_pos_weight\": scale_pos_weight_val\n",
    "        }\n",
    "        mlflow.log_dict(dataset_info, \"dataset_info.json\")\n",
    "\n",
    "    return test_avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING MODEL OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize', study_name='xgboost_tomeklinks_optimization')\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# Print optimization results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Test Average Precision: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best run ID: {best_run_id}\")\n",
    "\n",
    "# Register the best model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REGISTERING BEST MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_name = \"fraud_detection_xgboost_tomeklinks\"\n",
    "\n",
    "try:\n",
    "    # Register the model\n",
    "    model_version = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{best_run_id}/model\",\n",
    "        name=model_name,\n",
    "        tags={\n",
    "            \"model_type\": \"XGBoost\",\n",
    "            \"resampling\": \"TomekLinks\",\n",
    "            \"optimization_trials\": 30,\n",
    "            \"best_cv_avg_precision\": best_avg_precision,\n",
    "            \"hardware\": \"CPU_i5_10th_gen_12GB\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Model registered successfully!\")\n",
    "    print(f\"Model name: {model_name}\")\n",
    "    print(f\"Model version: {model_version.version}\")\n",
    "\n",
    "    # Transition model to Staging\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        stage=\"Staging\",\n",
    "        archive_existing_versions=False\n",
    "    )\n",
    "\n",
    "    print(f\"Model version {model_version.version} promoted to Staging!\")\n",
    "\n",
    "    # Add model version description\n",
    "    client.update_model_version(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        description=f\"Best XGBoost model with TomekLinks resampling. \"\n",
    "                   f\"Optimized using 30 Optuna trials on test set. \"\n",
    "                   f\"Best Test Average Precision: {best_avg_precision:.4f}. \"\n",
    "                   f\"Trained on CPU (i5 10th gen, 12GB RAM).\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during model registration: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
